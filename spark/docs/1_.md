## Spark DataFrame, SparkSQL

**데이터프레임 준비**

```scala
//DataFrame생성을 위해 데이터를 담는 클래스
case class Dessert(menuId:String, name:String, 		           price:Int, kcal:Int)
// 데이터를 담은 RDD를 만든다.
val dessertRDD = sc.textFile("data/dessert-menu.csv")
// DataFrame으로 만들기위한 RDD를 만든다.
val dessertObjRDD = dessertRDD.map{record =>
    // 쉼표단위로 자른다.
    val splittedLine = record.split(",")
    // Dessert 객체로 만든다
	Dessert(splittedLine(0),splittedLine(1),
    splittedLine(2).toInt,splittedLine(3).toInt)
}
		val dessertDF = dessertObjRDD.toDF
		// spark sql 사용을 위한 HiveContext 객체를 생성
		import org.apache.spark.sql.hive.HiveContext
		val sqlContext = new HiveContext(sc)
		// sqlContext 객체를 만들고 import 해야함
		import sqlContext.implicits._
		// DataFrame을 Table로 등록한다.
		dessertDF.registerTempTable("dessert_table")
```
**sql 명령문을 이용하는 방법**

`dessertDF.registerTempTable("dessert_table")` 을 사용해야함

```scala
//정렬
val sortedDF = sqlContext.sql(
"select name, price from dessert_table "
+"where price>=5200 "
+"order by price asc"
)
```

```scala
//집계
val sumDF1 = sqlContext.sql(
    "select sum(price) from dessert_table "
    +"where kcal>=300"
)
```
**RDD.toDF 함수를 사용하는 방법**

```scala
//정렬
val sortedDF3 = dessertDF.select($"name",$"price")
						 .where($"price">=5200)
						 .orderBy($"price".asc)
```

```scala
//집계
val sumDF2 = dessertDF.where($"kcal">=300).agg(sum($"price"))
```









