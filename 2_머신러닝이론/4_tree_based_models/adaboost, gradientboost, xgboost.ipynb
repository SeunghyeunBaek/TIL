{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* bagging\n",
    "    * 다수의 표본을 추출하고 tree 모델간의 결과를 종합\n",
    "    * 병렬적으로 진행되며 부트스트랩과정 포함\n",
    "* boosting\n",
    "    * 오차를 예측하는 모델을 생성하고 모델을 합친다.\n",
    "    * 순차적으로 진행되며 부트스트랩과정이 없다.\n",
    "* Adaboost\n",
    "    * 시행 n 에서\n",
    "        1. 시행 n-1에서 잘 분류된 데이터의 가중치를 내린다.\n",
    "        2. 시행 n-1에서 잘못분류된 데이터의 가중치를 올린다.\n",
    "        3. 분류한다.\n",
    "        4. 분류결과 데이터를 시행 n+1로 넘긴다.\n",
    "    * 모든 시행에서 나온 model에 대해 가중치를 곱하고 더한다.\n",
    "    * procedure\n",
    "        1. 관측값 가중치를 초기화한다.\n",
    "            * $w_{i} = 1/N, i = 1, 2, ... N$ where N is number of observations\n",
    "        2. for all models( m = 1, 2, .... j )\n",
    "           1. 분류기 $Gm(x)$를 가중치 $w_{i}$로 적합화한다.\n",
    "           2. 모델 내의 모든 관측값($x_{i}$)에 대해 손실함수를 계산한다.\n",
    "               * $ L_{m} = \\Sigma w_{m, i}I(y_{i} \\ne G_{m}(x_{i}))$\n",
    "               * $I(x)$: 조건에 따라 1, 0 을 반환. 즉 손실함수는 틀린 데이터에 대한 가중치의 합이다.\n",
    "           3. $error$ 비율을 계산한다. 전체 관측값 가중치합에 대한 틀린 관측값 가중치합의 비율이다.\n",
    "               * $ err_{m} = \\frac{\\Sigma w_{i}I(y_{i} \\ne G_{m}(x_{i}))}{\\Sigma w_{i}}$\n",
    "           4. 모델에 대한 가중치를 계산한다.\n",
    "               * $ \\alpha_{m} = \\frac{1-err_{m}}{err{m}} $\n",
    "               * err 이 낮은 모델이 더 가중치가 크다.\n",
    "           5. 데이터에 대한 가중치를 조정한다, 맞춘 관측치는 작게, 틀린 관측치는 크게(boosting) 한다.\n",
    "               * $ w_{m, i} = w_{m-1, i} * \\exp(\\alpha_{m} * I(y_{i} \\ne G_{m}(x_{i}))$\n",
    "               * 모델이 결과를 맞춘경우 원래 가중치의 exp(alpha)를 곱한다.\n",
    "           6. 최종함수를 만든다. 약한 모델들의 결과를 가중합한 결과가 양수면 1, 음수면 -1 을 반환한다.\n",
    "               * $G(x) = sign(\\Sigma \\alpha_{m}G_{m}(x))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'C:/Users/wonca/Documents/git_repositories/TIL/2_머신러닝이론/4_tree_based_models/data/'\n",
    "file_name = 'WA_Fn-UseC_-HR-Employee-Attrition.csv'\n",
    "hr_df = pd.read_csv(root + file_name)\n",
    "\n",
    "# ylabel\n",
    "y = hr_df['Attrition'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "hr_df['y'] = y\n",
    "\n",
    "# 더미변수 생성\n",
    "categorical_cols = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'OverTime']\n",
    "dummy_cols = []\n",
    "for cat_col in categorical_cols:\n",
    "    dummy_col = pd.get_dummies(hr_df[cat_col], prefix=cat_col)\n",
    "    dummy_cols.append(dummy_col)\n",
    "\n",
    "# 연속형 변수\n",
    "origianl_numeric_cols = hr_df.select_dtypes(include=np.int64).columns.tolist()\n",
    "remove_cols = ['EmployeeCount', 'EmployeeNumber', 'StandardHours']\n",
    "numeric_cols = [el for el in origianl_numeric_cols if el not in remove_cols]\n",
    "numeric_df = hr_df[numeric_cols]\n",
    "\n",
    "# 더미변수 + 연속형변수\n",
    "hr_new_df = pd.concat(dummy_cols + [numeric_df], axis=1)\n",
    "\n",
    "# train test splitㅠ\n",
    "x = hr_new_df.drop(['y'], axis=1)\n",
    "y = hr_new_df['y']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=1,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort=False,\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=0.05, n_estimators=5000, random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기본 분류기로 DT 선택\n",
    "dt_base_clf = DecisionTreeClassifier(criterion='gini', max_depth=1)\n",
    "adaboost_clf = AdaBoostClassifier(base_estimator=dt_base_clf,\n",
    "                                  n_estimators=5000,\n",
    "                                  learning_rate=.05,\n",
    "                                  random_state=42)\n",
    "\n",
    "adaboost_clf.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pre</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Act</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>844</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pre    0    1\n",
       "Act          \n",
       "0    844    9\n",
       "1     55  121"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = adaboost_clf.predict(x_train)\n",
    "pd.crosstab(y_train, y_train_pred, colnames=['Pre'], rownames=['Act'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       853\n",
      "           1       0.93      0.69      0.79       176\n",
      "\n",
      "    accuracy                           0.94      1029\n",
      "   macro avg       0.93      0.84      0.88      1029\n",
      "weighted avg       0.94      0.94      0.93      1029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pre</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Act</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pre    0   1\n",
       "Act         \n",
       "0    360  20\n",
       "1     38  23"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = adaboost_clf.predict(x_test)\n",
    "pd.crosstab(y_test, y_test_pred, colnames=['Pre'], rownames=['Act'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93       380\n",
      "           1       0.53      0.38      0.44        61\n",
      "\n",
      "    accuracy                           0.87       441\n",
      "   macro avg       0.72      0.66      0.68       441\n",
      "weighted avg       0.85      0.87      0.86       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 오차항을 예측하는 모델을 가중합한다.\n",
    "    1. 초기관측값에 대해 모델링한다.\n",
    "        * Y = F(x) + 오차항1\n",
    "    2. 오차항 1에 대해 모델링하고, 설명변수를 F(x)에 추가한다.\n",
    "        * 오차항1 = G(x) + 오차항2\n",
    "    3. 오차항 2에 대해 모델링하고 설명변수를 G(x)에 추가한다.\n",
    "        * 오차항2 = H(x) + 오차항3\n",
    "    4. F, G, X를 합산(혹은 가중합산)한다.\n",
    "        * Y = F(X) + G(X) + H(x) + 오차항3\n",
    "* GB의 3가지 요소\n",
    "    * 손실함수: 회귀문제는 rmse, 분류문제는 로그우도 사용. 각 단계에서 이전단계에서 설명하지 못한 손실에 대해 최적화를 수행한다\n",
    "    * 약한분류기: 결정트리 사용\n",
    "    * 손실함수를 최적화하기 위한 약한 분류기: 손실함수의 기울기가 감소하는 방향으로 새로운 트리가 하나씩 추가된다.\n",
    "* procedure\n",
    "    1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(loss='deviance', \n",
    "                                    learning_rate = .05, \n",
    "                                    n_estimators= 5000, \n",
    "                                    min_samples_split= 2, \n",
    "                                    min_samples_leaf= 1, \n",
    "                                    max_depth = 1, \n",
    "                                    random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.05, loss='deviance', max_depth=1,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=5000,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=42, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       853\n",
      "           1       0.98      0.72      0.83       176\n",
      "\n",
      "    accuracy                           0.95      1029\n",
      "   macro avg       0.96      0.86      0.90      1029\n",
      "weighted avg       0.95      0.95      0.95      1029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = gb_clf.predict(x_train)\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       380\n",
      "           1       0.57      0.39      0.47        61\n",
      "\n",
      "    accuracy                           0.88       441\n",
      "   macro avg       0.74      0.67      0.70       441\n",
      "weighted avg       0.86      0.88      0.87       441\n",
      "\n",
      "[[362  18]\n",
      " [ 37  24]]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = gb_clf.predict(x_test)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.02, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=1, missing=None, n_estimators=5000, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(max_depth=2, \n",
    "                            n_estimators=5000,\n",
    "                            learning_rate = .02, \n",
    "                            random_state= 42)\n",
    "xgb_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       853\n",
      "           1       1.00      0.98      0.99       176\n",
      "\n",
      "    accuracy                           1.00      1029\n",
      "   macro avg       1.00      0.99      0.99      1029\n",
      "weighted avg       1.00      1.00      1.00      1029\n",
      "\n",
      "[[853   0]\n",
      " [  4 172]]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = xgb_clf.predict(x_train)\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93       380\n",
      "           1       0.54      0.36      0.43        61\n",
      "\n",
      "    accuracy                           0.87       441\n",
      "   macro avg       0.72      0.66      0.68       441\n",
      "weighted avg       0.85      0.87      0.86       441\n",
      "\n",
      "[[361  19]\n",
      " [ 39  22]]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = xgb_clf.predict(x_test)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
