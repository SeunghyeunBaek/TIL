{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T04:27:27.562166Z",
     "start_time": "2019-08-04T04:27:27.556678Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T04:27:29.438644Z",
     "start_time": "2019-08-04T04:27:28.374718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T04:27:31.442190Z",
     "start_time": "2019-08-04T04:27:31.423341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(1)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# placeholder 정의\n",
    "x = tf.placeholder('float', shape=[None, 784])\n",
    "y_true = tf.placeholder('float', shape=[None, 10])\n",
    "\n",
    "x_img = tf.reshape(x, [-1, 28, 28, 1])  # 784 = 28 * 28\n",
    "x_img.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 합성곱 계층\n",
    "    * feature map의 집합을 말한다.\n",
    "    * 각 feature map(kernel, filter)는 하나의 특징을 검출한다.\n",
    "    * cnn은 입력 계층의 일부 데이터만 은닉 계층에 연결\n",
    "    * w, b(kernel, filter, feature map) 를 모든 은닉계층이 공유 => 가중치 매개 변수 감소\n",
    "    * 5*5 window 사용:  28 * 28 => 24 * 24(28-5+1)\n",
    "    * stride: 윈도우가 한번에 움직이는 거리\n",
    "    * padding: 테두리의 크기\n",
    "* 풀링 계층\n",
    "    * 데이터 압축\n",
    "    * ex: max pooling은 2x2 영역에서 가장 큰 값을 선택해 정보를 압축한다.\n",
    "    * 특징의 정확한 위치보다는 다른 특징과의 상대적 위치가 중요함.\n",
    "* 차원 변화\n",
    "    * 입력 계층(28x28)\n",
    "    * 합성곱 계층(None x 24 x 24, window=5, stride=1)\n",
    "    * 풀링 계층(None x 12 x 12, maxpulling) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T04:38:46.495482Z",
     "start_time": "2019-08-04T04:38:46.487548Z"
    }
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    # w 초기화\n",
    "    # truncated normal: 정규분포를 따르는 수열 생성, 2sigma 이상인 값은 제외\n",
    "    init = tf.truncated_normal(shape, stddev=.1)\n",
    "    return tf.Variable(init)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    # b 초기화, 0.1\n",
    "    init = tf.constant(.1, shape=shape)\n",
    "    return tf.Variable(init)\n",
    "\n",
    "\n",
    "def conv2d(x, w):\n",
    "    # 합성곱 계층\n",
    "    # stride: The stride of the sliding window for each dimension of input\n",
    "    return tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    # ksize: 커널 크기 2x2\n",
    "    # strides: 2x2\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T04:38:47.072273Z",
     "start_time": "2019-08-04T04:38:46.979273Z"
    }
   },
   "outputs": [],
   "source": [
    "## layer 1\n",
    "# window: 5x5, 32개 필터 정의\n",
    "# 세번째 원소는 color\n",
    "w_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_img, w_conv1) + b_conv1) # relu\n",
    "h_pool1 = max_pool_2x2(h_conv1)  # pooling\n",
    "\n",
    "## layer2\n",
    "# 32: conv1에서 출력 크기\n",
    "# window: 5x5, 64개 필터 정의\n",
    "w_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, w_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "\n",
    "## output\n",
    "# 1024뉴런\n",
    "w_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])  # 직렬화\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, w_fc1) + b_fc1)\n",
    "\n",
    "# dropout\n",
    "keep_prob = tf.placeholder('float')  # 드롭아웃 되지않을 확률\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# softmax\n",
    "w_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])  # 0-10\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, w_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T04:46:22.080551Z",
     "start_time": "2019-08-04T04:45:57.204622Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " iter 0 training accuracy: 0.05000000074505806\n",
      " iter 10 training accuracy: 0.20000000298023224\n",
      " iter 20 training accuracy: 0.5\n",
      " iter 30 training accuracy: 0.6100000143051147\n",
      " iter 40 training accuracy: 0.6800000071525574\n",
      " iter 50 training accuracy: 0.8299999833106995\n",
      " iter 60 training accuracy: 0.8100000023841858\n",
      " iter 70 training accuracy: 0.8700000047683716\n",
      " iter 80 training accuracy: 0.8100000023841858\n",
      " iter 90 training accuracy: 0.8399999737739563\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "## train model\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    cross_entropy = -tf.reduce_sum(y_true * tf.log(y_conv))  # loss function\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cross_entropy)  # optimizer\n",
    "    tf.summary.scalar('loss', cross_entropy)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_pred = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_true, 1))  # y_true is one-hot encoded\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, 'float'))  # metric: accuracy\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())  # 변수 초기화\n",
    "\n",
    "writer = tf.summary.FileWriter('./logs/cnn_test')\n",
    "writer.add_graph(sess.graph)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "for i in range(100):\n",
    "    batch = mnist.train.next_batch(100)  # 100개씩 배치학습\n",
    "    summary, train_accuracy = sess.run([merged, accuracy], feed_dict={x: batch[0], y_true: batch[1], keep_prob: 1})\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y_true: batch[1], keep_prob: 0.5})\n",
    "    writer.add_summary(summary, i)\n",
    "    if i%10 == 0:\n",
    "        print(f' iter {i} training accuracy: {train_accuracy}')\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T04:41:18.167297Z",
     "start_time": "2019-08-04T04:41:15.386723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8870000243186951\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = sess.run(accuracy, feed_dict={x: mnist.test.images, y_true: mnist.test.labels, keep_prob: 1})\n",
    "print(f'test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T04:41:19.270680Z",
     "start_time": "2019-08-04T04:41:19.214604Z"
    }
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
